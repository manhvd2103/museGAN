import torch
import numpy as np

class LayerNorm(torch.nn.Module):
    """An implementation of Layer normalization that does not require size
    information. Copied from https://github.com/pytorch/pytorch/issues/1959."""
    def __init__(self, n_features, eps=1e-5, affine=True):
        super().__init__()
        self.n_features = n_features
        self.affine = affine
        self.eps = eps
        if self.affine:
            self.gamma = torch.nn.Parameter(torch.Tensor(n_features).uniform_())
            self.beta = torch.nn.Parameter(torch.zeros(n_features))

    def forward(self, x):
        shape = [-1] + [1] * (x.dim() - 1)
        mean = x.view(x.size(0), -1).mean(1).view(*shape)
        std = x.view(x.size(0), -1).std(1).view(*shape)
        y = (x - mean) / (std + self.eps)
        if self.affine:
            shape = [1, -1] + [1] * (x.dim() - 2)
            y = self.gamma.view(*shape) * y + self.beta.view(*shape)
        return y
    
class DiscriminatorBlock(torch.nn.Module):
    def __init__(self, in_dim, out_dim, kernel, stride):
        super().__init__()
        self.transconv = torch.nn.Conv3d(in_dim, out_dim, kernel, stride)
        self.layernorm = LayerNorm(out_dim)
    
    def forward(self, x):
        x = self.transconv(x)
        x = self.layernorm(x)
        return torch.nn.functional.leaky_relu(x)
    
class Discriminator(torch.nn.Module):
    """A convolutional neural network (CNN) based discriminator. The
    discriminator takes as input either a real sample (in the training data) or
    a fake sample (generated by the generator) and outputs a scalar indicating
    its authentity.
    """
    def __init__(self):
        super().__init__()
        self.conv0 = torch.nn.ModuleList([
            DiscriminatorBlock(1, 16, (1, 1, 12), (1, 1, 12)) for _ in range(4)
        ])
        self.conv1 = torch.nn.ModuleList([
            DiscriminatorBlock(16, 16, (1, 4, 1), (1, 4, 1)) for _ in range(4)
        ])
        self.conv2 = torch.nn.Sequential(
            DiscriminatorBlock(16 * 4, 64, (1, 1, 3), (1, 1, 1)),
            DiscriminatorBlock(64, 128, (1, 1, 2), (1, 1, 2)),
            DiscriminatorBlock(128, 128, (1, 1, 2), (1, 1, 2)),
            DiscriminatorBlock(128, 256, (1, 2, 1), (1, 2, 1)),
            DiscriminatorBlock(256, 256, (1, 2, 1), (1, 2, 1)),
            DiscriminatorBlock(256, 512, (2, 1, 1), (1, 1, 1)),
            DiscriminatorBlock(512, 512, (3, 1, 1), (3, 1, 1))
        )
        self.dense = torch.nn.Linear(512, 1)

    def forward(self, x):
        #print('d_input', x.shape)
        x = x.view(-1, 4, 4, 16, 72)
        x = [conv(x[:, [i]]) for i, conv in enumerate(self.conv0)]
        x = torch.cat([conv(x_) for x_, conv in zip(x, self.conv1)], 1)
        x = self.conv2(x)
        x = x.view(-1, 512)
        x = self.dense(x)
        return x
     

if __name__ == '__main__':
    input = torch.randn(3, 4, 64, 72).detach()
    dis_net = Discriminator()
    out = dis_net(input)
    print(out.shape)